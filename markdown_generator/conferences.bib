@inproceedings{Harrison2014,
abstract = {{\textcopyright} 2014 IEEE. The vector evaluated particle swarm optimization (VEPSO) algorithm is a multi-swarm variation of the traditional particle swarm optimization (PSO) used to solve static multi-objective optimization problems (MOOPs). Recently, the dynamic VEPSO (DVEPSO) algorithm was proposed as an extension to VEPSO enabling the algorithm to handle dynamic MOOPs (DMOOPs). While DVEPSO has been successful at handling DMOOPs, the change detection mechanism relied on observing changes in objective space. An alternative strategy is proposed by using charged PSO (CPSO) sub-swarms with decision space change detection to address the outdated memory issue observed in vanilla PSO. This dynamic PSO variant allows for (implicit) decision space tracking not seen in DVEPSO while implicitly handling the diversity issue seen in dynamic environments. The proposed charged VEPSO is compared to DVEPSO on a wide variety of dynamic environment types. Results indicated that, in general, the proposed charged VEPSO outperformed the existing DVEPSO. Further, charged VEPSO exhibited better front-tracking abilities, while DVEPSO was superior with regards to locating the Pareto front.},
author = {Harrison, Kyle Robert and Ombuki-Berman, Beatrice M. and Engelbrecht, Andries P.},
booktitle = {2014 IEEE Congress on Evolutionary Computation (CEC)},
doi = {10.1109/CEC.2014.6900399},
isbn = {978-1-4799-1488-3},
month = {jul},
pages = {1929--1936},
publisher = {IEEE},
title = {{Dynamic multi-objective optimization using charged vector evaluated particle swarm optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6900399 https://ieeexplore.ieee.org/document/6900399},
year = {2014}
}
@inproceedings{Harrison2017,
abstract = {{\textcopyright} 2017 IEEE. Particle swarm optimization (PSO) is a stochastic search algorithm based on the social dynamics of a flock of birds. The performance of the PSO algorithm is known to be sensitive to the values assigned to its control parameters. While many studies have provided reasonable ranges in which to initialize the parameters based on their long-term behaviours, such previous studies fail to quantify the empirical performance of parameter configurations across a wide variety of benchmark problems. This paper specifically address this issue by examining the performance of a set of 1012 parameter configurations of the PSO algorithm over a set of 22 benchmark problems using both the global-best and local-best topologies. Results indicate that, in general, parameter configurations which are within close proximity to the boundaries of the best-known theoretically-defined convergent region lead to better performance than configurations which are further away. Moreover, results indicate that neighbourhood topology plays a far more significant role than modality and separability when determining the regions in parameter space which perform well.},
author = {Harrison, Kyle Robert and Ombuki-Berman, Beatrice M. and Engelbrecht, Andries P.},
booktitle = {2017 IEEE Congress on Evolutionary Computation (CEC)},
doi = {10.1109/CEC.2017.7969333},
isbn = {978-1-5090-4601-0},
month = {jun},
pages = {349--356},
publisher = {IEEE},
title = {{Optimal parameter regions for particle swarm optimization algorithms}},
url = {http://ieeexplore.ieee.org/document/7969333/},
year = {2017}
}
@inproceedings{Harrison2019,
abstract = {{\textcopyright} 2019 IEEE. It is well known that tuning a meta-heuristic optimizer is a challenging, yet rewarding process. Despite the benefits of a properly tuned optimizer, there is very little that is understood about the actual tuning process - many automated parameter tuning methods use an assumption that parameter configurations near a promising configuration will also be promising. However, this assumption has not been verified, in general. While the field of fitness landscape analysis can provide insight into the difficulty of an optimization problem, these techniques have not yet been applied to the parameter tuning problem. This paper proposes a methodology to apply standard techniques from fitness landscape analysis to the parameter configuration landscape of an arbitrary optimizer. This allows the characterization of the parameter tuning problem for an arbitrary optimizer on an arbitrary optimization problem. The proposed methodology is then investigated for the particle swarm optimization (PSO) algorithm on 20 benchmark problems in both 10 and 30 dimensions. The results indicate that the parameter configuration landscape of the PSO algorithm is globally unimodal, yet not necessarily an easy landscape to search. Furthermore, it is found that the characteristics of the PSO parameter configuration landscape do not correlate with the characteristics of the target benchmark problems.},
author = {Harrison, Kyle Robert and Ombuki-Berman, Beatrice M. and Engelbrecht, Andries P.},
booktitle = {2019 IEEE Congress on Evolutionary Computation (CEC)},
doi = {10.1109/CEC.2019.8790242},
isbn = {978-1-7281-2153-6},
keywords = {control parameter tuning,fitness landscape analysis,parameter configuration landscape,particle swarm optimization,self-adaptive},
month = {jun},
pages = {808--814},
publisher = {IEEE},
title = {{The Parameter Configuration Landscape: A Case Study on Particle Swarm Optimization}},
url = {https://ieeexplore.ieee.org/document/8790242/},
year = {2019}
}
